{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_onnx_tflite.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crqL63WrivSA",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch --> ONNX --> tflite Conversion\n",
        "Pytorch lovers, hard to jump ship. But `tflite` is to amazing that its one of the best AI format for mobile development.\n",
        "\n",
        "We are still not jumping ships but rather converting `.pth` model to `tflite` ;)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLe4tBuMik1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==1.14.0\n",
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.16.4\n",
        "!pip install  onnx-tf==1.5.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vQMPH3Jj9aI",
        "colab_type": "text"
      },
      "source": [
        "## Important Step\n",
        "Upload your pytorch model that needs to be converted, to colab, using GUI pane on the left hand side. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHQqOYh6j1fv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!onnx-tf convert -i \"mymodel.onnx\" -o  \"mymodel.pb\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3--TJLJOkonD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: This coveresion works with tensorflow < 2.0\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWBQZXsYj1Z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "# make a converter object from the saved tensorflow file\n",
        "converter = tf.lite.TFLiteConverter.from_frozen_graph('mymodel.pb',\n",
        "                                                      input_arrays=['input'],\n",
        "                                                      output_arrays=['output']\n",
        "                                                      )\n",
        "# tell converter which type of optimization techniques to use\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# convert the model \n",
        "tf_lite_model = converter.convert()\n",
        "# save the converted model \n",
        "open('mymodel.tflite', 'wb').write(tf_lite_model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}